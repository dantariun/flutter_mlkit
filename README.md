# mlkit_test

A learning Flutter project to detect facial expressions using Google ML Kit's face detection.

# using Library

- cupertino_icons: ^1.0.2
- camera: ^0.10.5+9
- flutter_riverpod: ^2.1.3
- http: ^0.13.5
- font_awesome_flutter: 10.3.0
- video_player: ^2.7.1
- video_player_avfoundation: ^2.4.10
- visibility_detector: 0.3.3
- path_provider_foundation: ^2.3.1
- permission_handler: ^10.2.0
- gallery_saver: 2.3.2
- shared_preferences: ^2.2.2
- image_picker: 0.8.6+1
- flutter_mask_view: ^1.0.2
- widget_mask: ^0.1.1
- percent_indicator: ^4.0.1
- step_progress_indicator: ^1.0.2
- image: ^4.1.6
- google_mlkit_face_detection: ^0.9.0
- vibration: ^1.8.4
- fluttertoast: ^8.2.4
- change_app_package_name: ^1.1.0

## Getting Started

This project is a starting point for a Flutter application.

A few resources to get you started if this is your first Flutter project:

- [Lab: Write your first Flutter app](https://docs.flutter.dev/get-started/codelab)
- [Cookbook: Useful Flutter samples](https://docs.flutter.dev/cookbook)

For help getting started with Flutter development, view the
[online documentation](https://docs.flutter.dev/), which offers tutorials,
samples, guidance on mobile development, and a full API reference.
